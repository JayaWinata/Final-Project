{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YSRj27sn29AK",
    "outputId": "dbac5d21-0a26-4157-ae22-135faab663dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sastrawi in c:\\users\\jayaw\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sastrawi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PZ4LqYbu3I0S",
    "outputId": "4b4e8db5-de3b-4dec-c9b2-73a8e0d073c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jayaw\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jayaw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jayaw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\jayaw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "\n",
    "from keras.layers import Dense, LeakyReLU, SimpleRNN, LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import datetime as dt\n",
    "import string\n",
    "import re\n",
    "\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "import csv\n",
    "import requests\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YaXTkBpi4GM6"
   },
   "source": [
    "# Memuat Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Eds8SyJe4Icf"
   },
   "outputs": [],
   "source": [
    "app_reviews_df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bgaI1Hrh4NPM"
   },
   "outputs": [],
   "source": [
    "jumlah_ulasan, jumlah_kolom = app_reviews_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "VCoo57l64QQo",
    "outputId": "5437f954-8066-4d11-9409-f710f7f6903b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rusak scan,Qris sulit terbaca kadang tidak bis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apk udah bagus tapi masih berasa berat , kalau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aplikasinya sangat bagus diawal2 nya terutama ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animasi promo yang kalian buat membuat aplikas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aplikasi makin kesini makin lemot saja... pada...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review\n",
       "0  Rusak scan,Qris sulit terbaca kadang tidak bis...\n",
       "1  Apk udah bagus tapi masih berasa berat , kalau...\n",
       "2  Aplikasinya sangat bagus diawal2 nya terutama ...\n",
       "3  Animasi promo yang kalian buat membuat aplikas...\n",
       "4  aplikasi makin kesini makin lemot saja... pada..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwuM2nHZDIx8"
   },
   "source": [
    "# Menghapus Data Kosong dan Data Duplikat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AQ1BbvD24aCd",
    "outputId": "639a18d5-5f40-4e6b-ac50-372baae2c861"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 126000 entries, 0 to 125999\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   Review  126000 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 984.5+ KB\n"
     ]
    }
   ],
   "source": [
    "app_reviews_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "7E6QKRn65G4L"
   },
   "outputs": [],
   "source": [
    "clean_df = app_reviews_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "y-NftO1s5InG"
   },
   "outputs": [],
   "source": [
    "clean_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K_l6kt1d5b6F",
    "outputId": "56b598b4-ad97-41fc-f5c2-d3f19799e02d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 124209 entries, 0 to 125999\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   Review  124209 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "clean_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vC7jdLPl5en_"
   },
   "outputs": [],
   "source": [
    "jumlah_ulasan_bersih, jumlah_kolom_bersih = clean_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dznFPnU35gPD"
   },
   "source": [
    "#Preprocessing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Sxot3PsR5inK"
   },
   "outputs": [],
   "source": [
    "def cleaningText(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text)\n",
    "    text = re.sub(r'#[A-Za-z0-9]+', '', text)\n",
    "    text = re.sub(r'RT[\\s]', '', text)\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'[0-9]+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.strip(' ')\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CA5GfgNQ5pnJ"
   },
   "outputs": [],
   "source": [
    "def casefoldingText(text):\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "j1h-BnY15rZ1"
   },
   "outputs": [],
   "source": [
    "def tokenizingText(text):\n",
    "    text = word_tokenize(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "hOnKdaTE5uC1"
   },
   "outputs": [],
   "source": [
    "def filteringText(text):\n",
    "    listStopwords = set(stopwords.words('indonesian'))\n",
    "    listStopwords1 = set(stopwords.words('english'))\n",
    "    listStopwords.update(listStopwords1)\n",
    "    listStopwords.update(['iya','yaa','gak','nya','na','sih','ku','di','ga','ya','gaa','loh','kah','woi','woii','woy'])\n",
    "    filtered = []\n",
    "    for txt in text:\n",
    "        if txt not in listStopwords:\n",
    "            filtered.append(txt)\n",
    "    text = filtered\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "G-DNFId75wHa"
   },
   "outputs": [],
   "source": [
    "def stemmingText(text):\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "\n",
    "    words = text.split()\n",
    "\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    stemmed_text = ' '.join(stemmed_words)\n",
    "\n",
    "    return stemmed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "mp4vgSO25yxm"
   },
   "outputs": [],
   "source": [
    "def toSentence(list_words):\n",
    "    sentence = ' '.join(word for word in list_words)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6xtKk7wO5zLt"
   },
   "outputs": [],
   "source": [
    "slangwords = {'@': 'di', 'abis': 'habis', 'wtb': 'beli', 'masi': 'masih', 'wts': 'jual', 'wtt': 'tukar', 'bgt': 'banget', 'maks': 'maksimal'}\n",
    "\n",
    "def fix_slangwords(text):\n",
    "    words = text.split()\n",
    "    fixed_words = []\n",
    "\n",
    "    for word in words:\n",
    "        if word.lower() in slangwords:\n",
    "            fixed_words.append(slangwords[word.lower()])\n",
    "        else:\n",
    "            fixed_words.append(word)\n",
    "\n",
    "    fixed_text = ' '.join(fixed_words)\n",
    "    return fixed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "gedtAWjP55f_"
   },
   "outputs": [],
   "source": [
    "clean_df['text_clean'] = clean_df['Review'].apply(cleaningText)\n",
    "clean_df['text_casefoldingText'] = clean_df['text_clean'].apply(casefoldingText)\n",
    "clean_df['text_slangwords'] = clean_df['text_casefoldingText'].apply(fix_slangwords)\n",
    "clean_df['text_tokenizingText'] = clean_df['text_slangwords'].apply(tokenizingText)\n",
    "clean_df['text_stopwords'] = clean_df['text_tokenizingText'].apply(filteringText)\n",
    "clean_df['final_text'] = clean_df['text_stopwords'].apply(toSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "I-T0PBXW6nUh",
    "outputId": "e4f6abb0-b889-4fc2-aef1-19ab3787a759"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_casefoldingText</th>\n",
       "      <th>text_slangwords</th>\n",
       "      <th>text_tokenizingText</th>\n",
       "      <th>text_stopwords</th>\n",
       "      <th>final_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rusak scan,Qris sulit terbaca kadang tidak bis...</td>\n",
       "      <td>Rusak scanQris sulit terbaca kadang tidak bisa...</td>\n",
       "      <td>rusak scanqris sulit terbaca kadang tidak bisa...</td>\n",
       "      <td>rusak scanqris sulit terbaca kadang tidak bisa...</td>\n",
       "      <td>[rusak, scanqris, sulit, terbaca, kadang, tida...</td>\n",
       "      <td>[rusak, scanqris, sulit, terbaca, kadang, ngeb...</td>\n",
       "      <td>rusak scanqris sulit terbaca kadang ngebaca su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apk udah bagus tapi masih berasa berat , kalau...</td>\n",
       "      <td>Apk udah bagus tapi masih berasa berat  kalau ...</td>\n",
       "      <td>apk udah bagus tapi masih berasa berat  kalau ...</td>\n",
       "      <td>apk udah bagus tapi masih berasa berat kalau b...</td>\n",
       "      <td>[apk, udah, bagus, tapi, masih, berasa, berat,...</td>\n",
       "      <td>[apk, udah, bagus, berasa, berat, latar, gamba...</td>\n",
       "      <td>apk udah bagus berasa berat latar gambar apk g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aplikasinya sangat bagus diawal2 nya terutama ...</td>\n",
       "      <td>Aplikasinya sangat bagus diawal nya terutama t...</td>\n",
       "      <td>aplikasinya sangat bagus diawal nya terutama t...</td>\n",
       "      <td>aplikasinya sangat bagus diawal nya terutama t...</td>\n",
       "      <td>[aplikasinya, sangat, bagus, diawal, nya, teru...</td>\n",
       "      <td>[aplikasinya, bagus, diawal, transaksinya, mem...</td>\n",
       "      <td>aplikasinya bagus diawal transaksinya membantu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animasi promo yang kalian buat membuat aplikas...</td>\n",
       "      <td>Animasi promo yang kalian buat membuat aplikas...</td>\n",
       "      <td>animasi promo yang kalian buat membuat aplikas...</td>\n",
       "      <td>animasi promo yang kalian buat membuat aplikas...</td>\n",
       "      <td>[animasi, promo, yang, kalian, buat, membuat, ...</td>\n",
       "      <td>[animasi, promo, aplikasi, patah, patah, mengs...</td>\n",
       "      <td>animasi promo aplikasi patah patah mengscroll ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aplikasi makin kesini makin lemot saja... pada...</td>\n",
       "      <td>aplikasi makin kesini makin lemot saja padahal...</td>\n",
       "      <td>aplikasi makin kesini makin lemot saja padahal...</td>\n",
       "      <td>aplikasi makin kesini makin lemot saja padahal...</td>\n",
       "      <td>[aplikasi, makin, kesini, makin, lemot, saja, ...</td>\n",
       "      <td>[aplikasi, kesini, lemot, koneksi, bagus, siny...</td>\n",
       "      <td>aplikasi kesini lemot koneksi bagus sinyal man...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review   \n",
       "0  Rusak scan,Qris sulit terbaca kadang tidak bis...  \\\n",
       "1  Apk udah bagus tapi masih berasa berat , kalau...   \n",
       "2  Aplikasinya sangat bagus diawal2 nya terutama ...   \n",
       "3  Animasi promo yang kalian buat membuat aplikas...   \n",
       "4  aplikasi makin kesini makin lemot saja... pada...   \n",
       "\n",
       "                                          text_clean   \n",
       "0  Rusak scanQris sulit terbaca kadang tidak bisa...  \\\n",
       "1  Apk udah bagus tapi masih berasa berat  kalau ...   \n",
       "2  Aplikasinya sangat bagus diawal nya terutama t...   \n",
       "3  Animasi promo yang kalian buat membuat aplikas...   \n",
       "4  aplikasi makin kesini makin lemot saja padahal...   \n",
       "\n",
       "                                text_casefoldingText   \n",
       "0  rusak scanqris sulit terbaca kadang tidak bisa...  \\\n",
       "1  apk udah bagus tapi masih berasa berat  kalau ...   \n",
       "2  aplikasinya sangat bagus diawal nya terutama t...   \n",
       "3  animasi promo yang kalian buat membuat aplikas...   \n",
       "4  aplikasi makin kesini makin lemot saja padahal...   \n",
       "\n",
       "                                     text_slangwords   \n",
       "0  rusak scanqris sulit terbaca kadang tidak bisa...  \\\n",
       "1  apk udah bagus tapi masih berasa berat kalau b...   \n",
       "2  aplikasinya sangat bagus diawal nya terutama t...   \n",
       "3  animasi promo yang kalian buat membuat aplikas...   \n",
       "4  aplikasi makin kesini makin lemot saja padahal...   \n",
       "\n",
       "                                 text_tokenizingText   \n",
       "0  [rusak, scanqris, sulit, terbaca, kadang, tida...  \\\n",
       "1  [apk, udah, bagus, tapi, masih, berasa, berat,...   \n",
       "2  [aplikasinya, sangat, bagus, diawal, nya, teru...   \n",
       "3  [animasi, promo, yang, kalian, buat, membuat, ...   \n",
       "4  [aplikasi, makin, kesini, makin, lemot, saja, ...   \n",
       "\n",
       "                                      text_stopwords   \n",
       "0  [rusak, scanqris, sulit, terbaca, kadang, ngeb...  \\\n",
       "1  [apk, udah, bagus, berasa, berat, latar, gamba...   \n",
       "2  [aplikasinya, bagus, diawal, transaksinya, mem...   \n",
       "3  [animasi, promo, aplikasi, patah, patah, mengs...   \n",
       "4  [aplikasi, kesini, lemot, koneksi, bagus, siny...   \n",
       "\n",
       "                                          final_text  \n",
       "0  rusak scanqris sulit terbaca kadang ngebaca su...  \n",
       "1  apk udah bagus berasa berat latar gambar apk g...  \n",
       "2  aplikasinya bagus diawal transaksinya membantu...  \n",
       "3  animasi promo aplikasi patah patah mengscroll ...  \n",
       "4  aplikasi kesini lemot koneksi bagus sinyal man...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jdYigDwg6qKs"
   },
   "source": [
    "# Memberi Label pada Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "mGvOMiBt6rSU"
   },
   "outputs": [],
   "source": [
    "lexicon_positive = dict()\n",
    "lexicon_negative = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "sDiRcW4r6tE9"
   },
   "outputs": [],
   "source": [
    "response = requests.get('https://raw.githubusercontent.com/angelmetanosaa/dataset/main/lexicon_positive.csv')\n",
    "response = requests.get('https://raw.githubusercontent.com/angelmetanosaa/dataset/main/lexicon_negative.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "bh6ZvoMt6ujx"
   },
   "outputs": [],
   "source": [
    "if response.status_code == 200:\n",
    "    reader = csv.reader(StringIO(response.text), delimiter=',')\n",
    "\n",
    "    for row in reader:\n",
    "        lexicon_positive[row[0]] = int(row[1])\n",
    "\n",
    "else:\n",
    "    print('Gagal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "7SSFIfST6wGJ"
   },
   "outputs": [],
   "source": [
    "if response.status_code == 200:\n",
    "    reader = csv.reader(StringIO(response.text), delimiter=',')\n",
    "\n",
    "    for row in reader:\n",
    "        lexicon_negative[row[0]] = int(row[1])\n",
    "\n",
    "else:\n",
    "    print('Gagal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "EtLUPdqa63pR"
   },
   "outputs": [],
   "source": [
    "def sentiment_analysis_lexicon_indonesia(text):\n",
    "    score = 0\n",
    "\n",
    "    for word in text:\n",
    "        if(word in lexicon_positive):\n",
    "            score = score + lexicon_positive[word]\n",
    "\n",
    "    for word in text:\n",
    "        if(word in lexicon_negative):\n",
    "            score = score + lexicon_negative[word]\n",
    "\n",
    "    polarity=''\n",
    "\n",
    "    if(score>0):\n",
    "        polarity = 'positive'\n",
    "    elif(score<0):\n",
    "        polarity = 'negative'\n",
    "    else:\n",
    "        polarity = 'neutral'\n",
    "\n",
    "    return score, polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_W9QNnjv65je",
    "outputId": "1f3573ea-eb62-4c5f-c5c2-85a000b17e87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polarity\n",
      "negative    117321\n",
      "neutral       6888\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "results = clean_df['text_stopwords'].apply(sentiment_analysis_lexicon_indonesia)\n",
    "results = list(zip(*results))\n",
    "clean_df['polarity_score'] = results[0]\n",
    "clean_df['polarity'] = results[1]\n",
    "print(clean_df['polarity'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5BNPxED68ke"
   },
   "source": [
    "# Data Splitting dan Ektraksi Fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "LSMod24ZQ-aX"
   },
   "outputs": [],
   "source": [
    "x = clean_df['final_text']\n",
    "y = clean_df['polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "I0ayRwtgQ7Wg"
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "rvUajze2QrC5"
   },
   "outputs": [],
   "source": [
    "x_train, x_temp, y_train, y_temp = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "QXpdn1Ae7PL-"
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=200, min_df=17, max_df=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "6cijH2-Q7PzF"
   },
   "outputs": [],
   "source": [
    "x_train_tfidf = tfidf.fit_transform(x_train)\n",
    "x_val_tfidf = tfidf.transform(x_val)\n",
    "x_test_tfidf = tfidf.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Ia0n5bka7RbG"
   },
   "outputs": [],
   "source": [
    "features_df = pd.DataFrame(x_train_tfidf.toarray(), columns=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "cFGQvQb67S7S",
    "outputId": "5255f9df-09f4-442a-d77f-5b3d605c9aad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admin</th>\n",
       "      <th>aja</th>\n",
       "      <th>aktif</th>\n",
       "      <th>akun</th>\n",
       "      <th>alasan</th>\n",
       "      <th>aman</th>\n",
       "      <th>aneh</th>\n",
       "      <th>apapun</th>\n",
       "      <th>apk</th>\n",
       "      <th>aplikasi</th>\n",
       "      <th>...</th>\n",
       "      <th>ulang</th>\n",
       "      <th>update</th>\n",
       "      <th>upgrade</th>\n",
       "      <th>verifikasi</th>\n",
       "      <th>versi</th>\n",
       "      <th>via</th>\n",
       "      <th>voucher</th>\n",
       "      <th>wa</th>\n",
       "      <th>wajah</th>\n",
       "      <th>yg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.335198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.318042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99362</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99363</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.262073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.394254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99364</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99365</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99366</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.350322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99367 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       admin       aja  aktif  akun  alasan      aman  aneh  apapun       apk   \n",
       "0        0.0  0.000000    0.0   0.0     0.0  0.335198   0.0     0.0  0.000000  \\\n",
       "1        0.0  0.000000    0.0   0.0     0.0  0.000000   0.0     0.0  0.000000   \n",
       "2        0.0  0.215716    0.0   0.0     0.0  0.000000   0.0     0.0  0.000000   \n",
       "3        0.0  0.000000    0.0   0.0     0.0  0.000000   0.0     0.0  0.000000   \n",
       "4        0.0  0.000000    0.0   0.0     0.0  0.000000   0.0     0.0  0.000000   \n",
       "...      ...       ...    ...   ...     ...       ...   ...     ...       ...   \n",
       "99362    0.0  0.000000    0.0   0.0     0.0  0.000000   0.0     0.0  0.000000   \n",
       "99363    0.0  0.000000    0.0   0.0     0.0  0.000000   0.0     0.0  0.000000   \n",
       "99364    0.0  0.000000    0.0   0.0     0.0  0.000000   0.0     0.0  0.000000   \n",
       "99365    0.0  0.000000    0.0   0.0     0.0  0.000000   0.0     0.0  0.000000   \n",
       "99366    0.0  0.000000    0.0   0.0     0.0  0.000000   0.0     0.0  0.350322   \n",
       "\n",
       "       aplikasi  ...     ulang    update  upgrade  verifikasi  versi   \n",
       "0      0.000000  ...  0.000000  0.000000      0.0         0.0    0.0  \\\n",
       "1      0.000000  ...  0.000000  0.000000      0.0         0.0    0.0   \n",
       "2      0.318042  ...  0.338364  0.000000      0.0         0.0    0.0   \n",
       "3      0.000000  ...  0.000000  0.000000      0.0         0.0    0.0   \n",
       "4      0.207114  ...  0.000000  0.000000      0.0         0.0    0.0   \n",
       "...         ...  ...       ...       ...      ...         ...    ...   \n",
       "99362  0.233016  ...  0.000000  0.000000      0.0         0.0    0.0   \n",
       "99363  0.262073  ...  0.000000  0.394254      0.0         0.0    0.0   \n",
       "99364  0.159598  ...  0.000000  0.000000      0.0         0.0    0.0   \n",
       "99365  0.165260  ...  0.000000  0.000000      0.0         0.0    0.0   \n",
       "99366  0.000000  ...  0.000000  0.000000      0.0         0.0    0.0   \n",
       "\n",
       "            via  voucher   wa  wajah        yg  \n",
       "0      0.000000      0.0  0.0    0.0  0.222624  \n",
       "1      0.000000      0.0  0.0    0.0  0.000000  \n",
       "2      0.000000      0.0  0.0    0.0  0.000000  \n",
       "3      0.000000      0.0  0.0    0.0  0.000000  \n",
       "4      0.000000      0.0  0.0    0.0  0.000000  \n",
       "...         ...      ...  ...    ...       ...  \n",
       "99362  0.000000      0.0  0.0    0.0  0.000000  \n",
       "99363  0.000000      0.0  0.0    0.0  0.000000  \n",
       "99364  0.173676      0.0  0.0    0.0  0.000000  \n",
       "99365  0.000000      0.0  0.0    0.0  0.000000  \n",
       "99366  0.000000      0.0  0.0    0.0  0.000000  \n",
       "\n",
       "[99367 rows x 200 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4-eQSuM775T"
   },
   "source": [
    "# Pembuatan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y5y5BCaR91_f",
    "outputId": "12629cae-1ad7-407d-f3ab-1532db448267"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jayaw\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\rnn\\lstm.py:148: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    LSTM(8, return_sequences=True, input_shape=(1, x_train_tfidf.shape[1])),\n",
    "    LSTM(16, return_sequences=True),\n",
    "    LSTM(32),\n",
    "    Dense(16),\n",
    "    LeakyReLU(),\n",
    "    Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "3u3A311k-3dq"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=1e-3), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 1, 8)              6688      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1, 16)             1600      \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 32)                6272      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                528       \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15139 (59.14 KB)\n",
      "Trainable params: 15139 (59.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFR3ET0AGln9"
   },
   "source": [
    "# Pelatihan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Fs0f3bV_S1V",
    "outputId": "03b48078-24c7-4e55-daae-63025bc5bb98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\jayaw\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jayaw\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "3106/3106 [==============================] - 33s 7ms/step - loss: 0.1136 - accuracy: 0.9543 - val_loss: 0.0760 - val_accuracy: 0.9544\n",
      "Epoch 2/10\n",
      "3106/3106 [==============================] - 19s 6ms/step - loss: 0.0712 - accuracy: 0.9591 - val_loss: 0.0740 - val_accuracy: 0.9573\n",
      "Epoch 3/10\n",
      "3106/3106 [==============================] - 21s 7ms/step - loss: 0.0703 - accuracy: 0.9593 - val_loss: 0.0746 - val_accuracy: 0.9554\n",
      "Epoch 4/10\n",
      "3106/3106 [==============================] - 37s 12ms/step - loss: 0.0698 - accuracy: 0.9598 - val_loss: 0.0738 - val_accuracy: 0.9570\n",
      "Epoch 5/10\n",
      "3106/3106 [==============================] - 51s 16ms/step - loss: 0.0695 - accuracy: 0.9600 - val_loss: 0.0740 - val_accuracy: 0.9565\n",
      "Epoch 6/10\n",
      "3106/3106 [==============================] - 46s 15ms/step - loss: 0.0693 - accuracy: 0.9594 - val_loss: 0.0739 - val_accuracy: 0.9571\n",
      "Epoch 7/10\n",
      "3106/3106 [==============================] - 51s 17ms/step - loss: 0.0690 - accuracy: 0.9603 - val_loss: 0.0735 - val_accuracy: 0.9577\n",
      "Epoch 8/10\n",
      "3106/3106 [==============================] - 36s 12ms/step - loss: 0.0687 - accuracy: 0.9604 - val_loss: 0.0738 - val_accuracy: 0.9556\n",
      "Epoch 9/10\n",
      "3106/3106 [==============================] - 21s 7ms/step - loss: 0.0684 - accuracy: 0.9606 - val_loss: 0.0737 - val_accuracy: 0.9573\n",
      "Epoch 10/10\n",
      "3106/3106 [==============================] - 20s 7ms/step - loss: 0.0681 - accuracy: 0.9613 - val_loss: 0.0742 - val_accuracy: 0.9570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x243520c72e0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_reshaped = np.reshape(x_train_tfidf.toarray(), (x_train_tfidf.shape[0], 1, x_train_tfidf.shape[1]))\n",
    "x_val_reshaped = np.reshape(x_val_tfidf.toarray(), (x_val_tfidf.shape[0], 1, x_val_tfidf.shape[1]))\n",
    "\n",
    "model.fit(x_train_reshaped, y_train, epochs=10, validation_data=(x_val_reshaped, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nop_wt5XGprx"
   },
   "source": [
    "# Prediksi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "0yJ2fDtyHnf9"
   },
   "outputs": [],
   "source": [
    "x_test_reshaped = np.reshape(x_test_tfidf.toarray(), (x_test_tfidf.shape[0], 1, x_test_tfidf.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gAzP5kr8AMPy",
    "outputId": "af7f5e24-a057-4168-a530-ddd8bc6ca780"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389/389 [==============================] - 8s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKAYQtotGzg_"
   },
   "source": [
    "# Evaluasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "9FmnU6h5H9Ik"
   },
   "outputs": [],
   "source": [
    "y_pred_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "e2_QejGd_35d"
   },
   "outputs": [],
   "source": [
    "accuracy = round(accuracy_score(y_pred_classes, y_test), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "taEdlr3UAkbh",
    "outputId": "35806f41-288d-4ed3-b6fa-4c08bf814da3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Model LSTM : 0.9609\n"
     ]
    }
   ],
   "source": [
    "print('Akurasi Model LSTM :', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WpZipQogG2DU",
    "outputId": "d9c46210-8f55-4d4b-b1cd-7fc3a6f82fe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     11747\n",
      "           1       0.65      0.60      0.63       674\n",
      "\n",
      "    accuracy                           0.96     12421\n",
      "   macro avg       0.81      0.79      0.80     12421\n",
      "weighted avg       0.96      0.96      0.96     12421\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WklxQCQSG8qS",
    "outputId": "4e9270c9-3636-49ec-e546-89effe738180"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11528,   219],\n",
       "       [  267,   407]], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBB0Vh-9HCNS"
   },
   "source": [
    "# Contoh Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "C0dsdiXqPU2e",
    "outputId": "aee6fe36-be72-4051-b30c-bb409e6d2747"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5510     nih apk ngeselin coba hp gk root muncul hp roo...\n",
       "80846    tolong diperbaiki transfer sibuk klo topup uan...\n",
       "62500    aman aman aja yah saldo kosong mantap lanjutin...\n",
       "32308                                  membantu bermanfaat\n",
       "93761    promo tp susah transaksinya aja bohong perbaik...\n",
       "Name: final_text, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = x_test.sample(n=5)\n",
    "test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "PZzscWabL6cQ"
   },
   "outputs": [],
   "source": [
    "test_sample_tfidf = tfidf.transform(test_sample)\n",
    "test_sample_reshaped = np.reshape(test_sample_tfidf.toarray(), (test_sample_tfidf.shape[0], 1, test_sample_tfidf.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rwS2pyyGMYPQ",
    "outputId": "282ecf07-417d-41e6-ba1f-ee07e1e0f5e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 139ms/step\n"
     ]
    }
   ],
   "source": [
    "predicted_values = model.predict(test_sample_reshaped)\n",
    "predicted_classes = np.argmax(predicted_values, axis=1)\n",
    "sentiment = encoder.inverse_transform(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Cm5ShFl6Uq5I",
    "outputId": "df8b677e-0764-4b55-ade5-38b9ca78cf50"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5510</th>\n",
       "      <td>nih apk ngeselin coba hp gk root muncul hp root memudahkan menyusahkan</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80846</th>\n",
       "      <td>tolong diperbaiki transfer sibuk klo topup uang sampe tertahan sehari menganggu</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62500</th>\n",
       "      <td>aman aman aja yah saldo kosong mantap lanjutin dana orang orang yg komen upgrade premium yah lemot</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32308</th>\n",
       "      <td>membantu bermanfaat</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93761</th>\n",
       "      <td>promo tp susah transaksinya aja bohong perbaiki alasannya signal lemah truss promo tp pake alias trouble teruss kecewa</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                         text   \n",
       "5510                                                   nih apk ngeselin coba hp gk root muncul hp root memudahkan menyusahkan  \\\n",
       "80846                                         tolong diperbaiki transfer sibuk klo topup uang sampe tertahan sehari menganggu   \n",
       "62500                      aman aman aja yah saldo kosong mantap lanjutin dana orang orang yg komen upgrade premium yah lemot   \n",
       "32308                                                                                                     membantu bermanfaat   \n",
       "93761  promo tp susah transaksinya aja bohong perbaiki alasannya signal lemah truss promo tp pake alias trouble teruss kecewa   \n",
       "\n",
       "      sentiment  \n",
       "5510   negative  \n",
       "80846  negative  \n",
       "62500  negative  \n",
       "32308  negative  \n",
       "93761  negative  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "pd.DataFrame({'text': test_sample, 'sentiment': sentiment})"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
